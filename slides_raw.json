[
    {
      "question": "Mô hình tuyến tính (linear model) là gì?",
      "answer": "Mô hình tuyến tính giả định rằng đầu ra (output) là sự kết hợp tuyến tính có trọng số của các đặc trưng đầu vào. Công thức: y = Σ(w_d * x_d) = w^T x."
    },
    {
      "question": "Ý nghĩa của vector trọng số w trong mô hình tuyến tính là gì?",
      "answer": "Vector trọng số w = [w1, w2, …, wD] xác định tầm quan trọng của từng đặc trưng đầu vào. Mỗi w_d cho biết mức đóng góp của đặc trưng x_d trong việc dự đoán đầu ra."
    },
    {
      "question": "Làm sao để tìm được trọng số tối ưu trong mô hình tuyến tính?",
      "answer": "Các trọng số tối ưu không được biết trước mà phải học thông qua việc giải một bài toán tối ưu hóa dựa trên dữ liệu huấn luyện."
    },
    {
      "question": "Mô hình tuyến tính có thể được sử dụng cho những bài toán nào?",
      "answer": "Linear Regression; hoặc như một khối cơ bản cho mô hình phức tạp hơn như phân loại (binary, multiclass, multi-output, multi-label) và học không giám sát (ví dụ: dimensionality reduction)."
    },
{
      "question": "Dữ liệu đầu vào của bài toán hồi quy tuyến tính gồm những gì?",
      "answer": "Dữ liệu huấn luyện gồm N cặp (x_n, y_n), trong đó x_n ∈ R^D là vector đặc trưng và y_n ∈ R là giá trị đầu ra thực."
    },
    {
      "question": "Mục tiêu của Linear Regression là gì?",
      "answer": "Mục tiêu là học một mô hình dự đoán đầu ra y cho các dữ liệu mới dựa trên dữ liệu huấn luyện."
    },
    {
      "question": "Giả định mô hình tuyến tính được viết như thế nào?",
      "answer": "Mỗi đầu ra y_n được xấp xỉ bởi f(x_n) = w^T x_n, với n = 1, 2, …, N. Dưới dạng ma trận, có thể viết gọn là y ≈ Xw."
    },
    {
      "question": "Hàm mất mát (loss function) trong hồi quy tuyến tính được định nghĩa như thế nào?",
      "answer": "Tổng loss trên tập huấn luyện là: L(w) = Σ (ℓ(y_n, w^T x_n)), trong đó ℓ đo lường sai số dự đoán giữa nhãn thật y_n và dự đoán w^T x_n."
    },
    {
      "question": "Điểm khác biệt của Linear Regression so với KNN hoặc Decision Tree là gì?",
      "answer": "Linear Regression có một hàm mục tiêu (loss function) rõ ràng và cụ thể để tối ưu hóa, trong khi KNN và Decision Tree không có hàm mục tiêu tường minh."
    },
    {
      "question": "Mục tiêu cuối cùng khi học hồi quy tuyến tính là gì?",
      "answer": "Mục tiêu là tìm vector trọng số w làm giảm thiểu loss trên dữ liệu huấn luyện và đồng thời tổng quát tốt trên dữ liệu kiểm thử."
    },
    {
      "question": "Linear regression được minh họa trực quan như thế nào?",
      "answer": "Nó giống như việc khớp một đường thẳng (line) hoặc một siêu phẳng (hyperplane) với một tập hợp các điểm dữ liệu."
    },
    {
      "question": "Điều gì xảy ra nếu quan hệ đầu vào–đầu ra không được mô hình hóa tốt bằng đường thẳng/phẳng?",
      "answer": "Khi quan hệ thực sự là phi tuyến (nonlinear curve/surface), một đường thẳng có thể không mô tả tốt dữ liệu."
    },
    {
      "question": "Trong trường hợp dữ liệu có quan hệ phi tuyến, mô hình tuyến tính có còn hữu ích không?",
      "answer": "Có. Ta có thể biến đổi đầu vào bằng một phép biến đổi φ(x), sau đó vẫn sử dụng mô hình tuyến tính: y ≈ w^T φ(x)."
    },
    {
      "question": "Phép biến đổi φ(x) có thể được thực hiện như thế nào?",
      "answer": "Phép biến đổi φ(x) có thể được xác định sẵn (predefined), hoặc được học bằng các phương pháp như kernel methods hay sử dụng mạng neural để trích xuất đặc trưng."
    },
    {
      "question": "Mô hình hồi quy tuyến tính sau khi học cần đảm bảo điều gì với dữ liệu kiểm thử?",
      "answer": "Đường thẳng/phẳng đã học phải dự đoán tốt cả với các dữ liệu chưa từng thấy (unseen test inputs)."
    },
{
      "question": "Làm thế nào để tìm điểm cực tiểu (minima) của hàm loss?",
      "answer": "Có thể sử dụng phép tính giải tích cơ bản (calculus) để tìm cực tiểu."
    },
    {
      "question": "Điều kiện tối ưu bậc một (first-order optimality) là gì?",
      "answer": "Gradient g phải bằng 0 tại điểm cực trị: g = ∇w L(w) = 0."
    },
    {
      "question": "Ý nghĩa của việc gọi là 'first order' là gì?",
      "answer": "Vì chỉ dùng gradient, cung cấp thông tin bậc một về hàm số đang được tối ưu."
    },
    {
      "question": "Phương pháp first-order optimality áp dụng được trong trường hợp nào?",
      "answer": "Chỉ hoạt động tốt cho các bài toán đơn giản, khi hàm mục tiêu là convex và không có ràng buộc trên các giá trị của w."
    },
    {
      "question": "Nếu giải được g = 0, ta thu được gì?",
      "answer": "Có thể tìm được nghiệm dạng đóng (closed form solution) cho w."
    },
    {
      "question": "Nếu không có nghiệm dạng đóng, gradient g được dùng thế nào?",
      "answer": "Có thể dùng trong các thuật toán tối ưu lặp (iterative optimization) như gradient descent (GD)."
    },
    {
      "question": "Ngay cả khi tồn tại nghiệm dạng đóng, gradient descent có thể hữu ích không?",
      "answer": "Có. Trong một số trường hợp, GD vẫn có thể hiệu quả hơn."
    },
{
      "question": "Có những loại loss function nào thường dùng trong regression?",
      "answer": "Một số loại loss function thường dùng: Squared loss, Absolute loss, Huber loss, và ε-insensitive loss (Vapnik loss)."
    },
    {
      "question": "Squared loss có đặc điểm gì?",
      "answer": "Squared loss được dùng rất phổ biến trong regression vì dễ giải bài toán tối ưu."
    },
    {
      "question": "Absolute loss có ưu điểm gì?",
      "answer": "Absolute loss tăng chậm hơn squared loss, phù hợp khi dữ liệu có outliers."
    },
    {
      "question": "Huber loss hoạt động như thế nào?",
      "answer": "Huber loss sử dụng squared loss cho lỗi nhỏ (|error| ≤ δ) và absolute loss cho lỗi lớn, phù hợp với dữ liệu có outliers."
    },
    {
      "question": "ε-insensitive loss (Vapnik loss) là gì?",
      "answer": "Đây là hàm loss bỏ qua các lỗi nhỏ (≤ ε) và tính absolute loss cho lỗi lớn hơn ε. Có thể thay absolute loss bằng squared loss."
    },
    {
      "question": "Việc chọn loss function phụ thuộc vào yếu tố nào?",
      "answer": "Thường phụ thuộc vào bản chất dữ liệu. Một số loss function giúp tối ưu dễ hơn các loss khác."
    },
{
      "question": "Gradient Descent được sử dụng để làm gì?",
      "answer": "Gradient Descent là một phương pháp tối ưu hóa lặp để tìm nghiệm tối ưu bằng cách di chuyển theo hướng ngược lại của gradient."
    },
    {
      "question": "Làm thế nào để cập nhật tham số w trong Gradient Descent?",
      "answer": "Tại mỗi vòng lặp t: tính gradient g^(t), chọn learning rate η_t, rồi cập nhật w^(t+1) = w^(t) - η_t g^(t)."
    },
    {
      "question": "Có thể dùng Gradient Descent cho bài toán maximization không?",
      "answer": "Có, ta dùng Gradient Ascent với công thức w^(t+1) = w^(t) + η_t g^(t)."
    },
    {
      "question": "Gradient cung cấp thông tin gì?",
      "answer": "Gradient cho biết hướng thay đổi nhanh nhất (steepest change) của giá trị hàm."
    },
    {
      "question": "Gradient Descent có đảm bảo hội tụ không?",
      "answer": "Với hàm convex, Gradient Descent sẽ hội tụ về global minima. Với hàm không convex, cần khởi tạo tốt để tránh local minima."
    },
    {
      "question": "Yếu tố quan trọng nào cần chú ý khi dùng Gradient Descent?",
      "answer": "Learning rate phải được chọn cẩn thận (cố định hoặc thích ứng). Ngoài ra cần kiểm soát điều kiện hội tụ."
    },
    {
      "question": "Tại sao phương pháp này gọi là iterative?",
      "answer": "Vì nó cần nhiều bước lặp (iterations) mới tìm được nghiệm tối ưu."
    },
{
      "question": "Loss function trong Linear Regression với squared loss được định nghĩa như thế nào?",
      "answer": "L(w) = Σ (y_n - w^T x_n)^2, với n chạy từ 1 đến N."
    },
    {
      "question": "Có thể viết loss function trên dưới dạng ma trận không?",
      "answer": "Có, trong ký hiệu ma trận: ||y - Xw||² = (y - Xw)^T (y - Xw)."
    },
    {
      "question": "Làm thế nào để tìm w tối ưu?",
      "answer": "Ta tìm w sao cho tối thiểu hóa squared loss, dùng điều kiện tối ưu bậc nhất."
    },
    {
      "question": "Bài toán Least Squares (LS) có đặc điểm gì?",
      "answer": "Đây là một bài toán cổ điển từ thế kỷ 18 (Gauss-Legendre) và có nghiệm đóng (closed form solution)."
    },
    {
      "question": "Công thức nghiệm đóng của Linear Regression là gì?",
      "answer": "w_LS = (Σ x_n x_n^T)^(-1) (Σ y_n x_n) = (X^T X)^(-1) X^T y."
    },
    {
      "question": "Nghiệm đóng có phổ biến trong ML không?",
      "answer": "Không, nghiệm đóng trong các bài toán Machine Learning là khá hiếm."
    },
    {
      "question": "Có khó khăn nào khi tính nghiệm đóng không?",
      "answer": "Có, việc nghịch đảo ma trận D×D có thể rất tốn kém. Sẽ có các cách xử lý khác được thảo luận sau."
    },
{
      "question": "Mục tiêu của phép chứng minh trong slide này là gì?",
      "answer": "Tìm nghiệm tối ưu (minima) của hàm loss L(w) = Σ (y_n - w^T x_n)^2."
    },
    {
      "question": "Bước đầu tiên để tìm nghiệm tối ưu là gì?",
      "answer": "Lấy đạo hàm bậc nhất của L(w) theo w và đặt bằng 0."
    },
    {
      "question": "Khi lấy đạo hàm ∂/∂w (y_n - w^T x_n)^2 thì ta được gì?",
      "answer": "Ta được Σ 2(y_n - w^T x_n)(-x_n)."
    },
    {
      "question": "Kết quả của đạo hàm ∂/∂w (w^T x_n) là gì?",
      "answer": "Kết quả bằng x_n, có cùng kích thước với w."
    },
    {
      "question": "Sau khi rút gọn, phương trình gradient bằng 0 có dạng gì?",
      "answer": "Σ 2(y_n - w^T x_n) x_n = 0."
    },
    {
      "question": "Làm sao để tách w trong phương trình trên?",
      "answer": "Viết lại thành Σ y_n x_n - Σ x_n x_n^T w = 0."
    },
    {
      "question": "Nghiệm cuối cùng của w là gì?",
      "answer": "w_LS = (Σ x_n x_n^T)^(-1) (Σ y_n x_n) = (X^T X)^(-1) X^T y."
    },
{
      "question": "Khi tối ưu hàm L(w) = Σ (y_n - w^T x_n)^2, ta thu được nghiệm như thế nào?",
      "answer": "w_LS = (Σ x_n x_n^T)^(-1) (Σ y_n x_n) = (X^T X)^(-1) X^T y."
    },
    {
      "question": "Vấn đề gì có thể xảy ra với ma trận X^T X?",
      "answer": "Ma trận X^T X có thể không khả nghịch, dẫn đến nghiệm tối ưu w_opt không duy nhất."
    },
    {
      "question": "Vấn đề thứ hai của lời giải này là gì?",
      "answer": "Hiện tượng overfitting, do chỉ tối ưu loss trên tập train. Các trọng số w có thể trở nên rất lớn để fit dữ liệu huấn luyện, nhưng hoạt động kém trên dữ liệu test."
    },
    {
      "question": "Giải pháp được đề xuất để khắc phục các vấn đề là gì?",
      "answer": "Tối ưu một hàm mục tiêu có regularization: L(w) + λ R(w)."
    },
    {
      "question": "Regularizer R(w) có vai trò gì?",
      "answer": "R(w) đo độ lớn (magnitude) của vector w, giúp ngăn w không trở nên quá lớn."
    },
    {
      "question": "Ý nghĩa của λ trong hàm mục tiêu là gì?",
      "answer": "λ ≥ 0 là siêu tham số điều chuẩn (regularization hyperparameter), kiểm soát mức độ regularize, cần điều chỉnh bằng cross-validation."
    },
    {
      "question": "Khi thêm regularization, ta thực chất đang tối ưu cái gì?",
      "answer": "Đang tối ưu tổng của training error và magnitude của vector w."
    },
  {
    "question": "Ý nghĩa của các tham số trong hồi quy tuyến tính?",
    "answer": "w (hệ số góc): cho biết khi x tăng 1 đơn vị thì y thay đổi trung bình bao nhiêu. b (hệ số chặn): giá trị dự đoán khi x=0."
  },
  {
    "question": "Hàm mất mát trong hồi quy tuyến tính là gì?",
    "answer": "Hàm mất mát phổ biến là Mean Squared Error (MSE): L(w,b) = (1/n) Σ (y_i - (w*x_i + b))^2."
  },
  {
    "question": "Gradient Descent là gì?",
    "answer": "Gradient Descent là thuật toán tối ưu để tìm w, b sao cho hàm mất mát nhỏ nhất. Nó điều chỉnh w, b theo hướng giảm sai số."
  },
  {
    "question": "Quy tắc cập nhật của Gradient Descent?",
    "answer": "w := w - α * ∂L/∂w, b := b - α * ∂L/∂b. Trong đó α là learning rate."
  },
  {
    "question": "Công thức đạo hàm trong Gradient Descent?",
    "answer": "∂L/∂w = (-2/n) Σ [ x_i * (y_i - (w*x_i + b)) ], ∂L/∂b = (-2/n) Σ [ y_i - (w*x_i + b) ]."
  },
  {
    "question": "Các bước thực hiện Gradient Descent?",
    "answer": "1. Khởi tạo w, b. 2. Tính gradient. 3. Cập nhật w, b. 4. Lặp lại cho đến khi hội tụ."
  },
{
    "question": "Evaluation Measures for Multi-class Classification là gì?",
    "answer": "Đây là tập hợp các phép đo đánh giá mô hình phân loại với nhiều lớp, bao gồm accuracy, confusion matrix, precision, recall, và F1-score."
  },
  {
    "question": "Công thức Accuracy trong multi-class classification?",
    "answer": "accuracy = (TP_total) / (TP_total + FP_total + FN_total + TN_total)"
  },
  {
    "question": "Công thức Precision cho từng lớp k?",
    "answer": "precision_k = TP_k / (TP_k + FP_k)"
  },
  {
    "question": "Công thức Recall cho từng lớp k?",
    "answer": "recall_k = TP_k / (TP_k + FN_k)"
  },
  {
    "question": "Công thức F1-score cho từng lớp k?",
    "answer": "F1_k = 2 * (precision_k * recall_k) / (precision_k + recall_k)"
  },
  {
    "question": "Macro average và Micro average khác nhau như thế nào?",
    "answer": "Macro-average tính trung bình số học trên từng lớp, Micro-average tính trên tổng TP, FP, FN trước khi tính chỉ số."
  },
  {
    "question": "Một số hàm mất mát khác cho Binary Classification ngoài Cross-Entropy?",
    "answer": "Có hinge loss, squared hinge, logistic loss, focal loss, exponential loss."
  },
  {
    "question": "Công thức Binary Cross-Entropy?",
    "answer": "L = -[ y * log(p) + (1 - y) * log(1 - p) ]"
  },
  {
    "question": "Công thức Hinge Loss?",
    "answer": "L = max(0, 1 - y * f(x)), với y ∈ {-1,+1}"
  },
  {
    "question": "Công thức Squared Hinge Loss?",
    "answer": "L = (max(0, 1 - y * f(x)))^2"
  },
  {
    "question": "Công thức Focal Loss?",
    "answer": "L = - (1 - p_t)^γ * log(p_t), với p_t = p nếu y=1, ngược lại 1-p"
  },
  {
    "question": "Linear Models for Classification là gì?",
    "answer": "Là các mô hình dựa trên hàm tuyến tính f(x)=w^T x + b, ví dụ như Logistic Regression, Perceptron, LDA, và SVM."
  },
  {
    "question": "Công thức Logistic Sigmoid trong phân loại?",
    "answer": "σ(z) = 1 / (1 + exp(-z)), p(y=1|x) = σ(w^T x + b)"
  },
  {
    "question": "Công thức Softmax cho phân loại đa lớp?",
    "answer": "p(C_k|x) = exp(w_k^T x + b_k) / Σ_j exp(w_j^T x + b_j)"
  },
  {
    "question": "Cross-Entropy Loss: The Gradient có đặc điểm gì?",
    "answer": "Đạo hàm của cross-entropy kết hợp với sigmoid/softmax rất đơn giản: gradient theo logits là (p - y)."
  },
  {
    "question": "Công thức Gradient cho Binary Cross-Entropy?",
    "answer": "dL/dz = σ(z) - y"
  },
  {
    "question": "Công thức Gradient cho Categorical Cross-Entropy?",
    "answer": "dL/dz_j = p_j - y_j (cho softmax + cross-entropy)"
  },
  {
    "question": "Loss Functions for Classification: Cross-Entropy là gì?",
    "answer": "Là hàm mất mát đo khoảng cách giữa phân phối thực tế (one-hot) và phân phối dự đoán, được dùng phổ biến nhất cho phân loại."
  },
  {
    "question": "Công thức Categorical Cross-Entropy?",
    "answer": "L = - Σ_{k=1..K} y_k log(p_k), với p_k = exp(z_k) / Σ_j exp(z_j)"
  },
{
    "question": "Loss Functions for Classification là gì?",
    "answer": "Là các hàm mất mát dùng để huấn luyện mô hình phân loại, nhằm đo độ sai lệch giữa nhãn dự đoán và nhãn thực tế."
  },
  {
    "question": "Các loại Loss phổ biến cho Classification?",
    "answer": "Bao gồm: Cross-Entropy Loss, Hinge Loss, Squared Hinge Loss, Logistic Loss, và Focal Loss."
  },
  {
    "question": "Công thức Cross-Entropy Loss cho nhị phân?",
    "answer": "L = - [ y * log(p) + (1 - y) * log(1 - p) ]"
  },
  {
    "question": "Công thức Cross-Entropy Loss cho đa lớp?",
    "answer": "L = - Σ_{k=1..K} y_k log(p_k), với p_k là xác suất softmax."
  },
  {
    "question": "Linear Classification: Interpreting weight vectors nghĩa là gì?",
    "answer": "Là cách hiểu các vector trọng số (w) trong mô hình tuyến tính để biết đặc trưng nào ảnh hưởng mạnh nhất đến quyết định phân loại."
  },
  {
    "question": "Ý nghĩa dấu và độ lớn của trọng số w?",
    "answer": "Dấu (+/-) cho biết ảnh hưởng tích cực hay tiêu cực đến xác suất một lớp; độ lớn |w_d| cho biết mức độ quan trọng của đặc trưng x_d."
  },
  {
    "question": "Công thức mô hình phân loại tuyến tính?",
    "answer": "f(x) = w^T x + b, trong đó w là vector trọng số, b là bias."
  },
  {
    "question": "Linear Models: The Decision Boundary là gì?",
    "answer": "Là đường hoặc siêu phẳng phân chia không gian đặc trưng thành các vùng quyết định cho từng lớp."
  },
  {
    "question": "Công thức biên quyết định trong 2D?",
    "answer": "w^T x + b = 0, đây là một đường thẳng phân chia mặt phẳng thành hai nửa."
  },
  {
    "question": "Công thức biên quyết định trong n-D?",
    "answer": "w^T x + b = 0 định nghĩa một siêu phẳng (hyperplane) trong không gian n chiều."
  },
  {
    "question": "Linear Models for Classification là gì?",
    "answer": "Là nhóm mô hình phân loại dựa trên tổ hợp tuyến tính của đầu vào, ví dụ Logistic Regression, Linear Discriminant Analysis (LDA), và Support Vector Machine (SVM)."
  },
  {
    "question": "Mô hình Logistic Regression thuộc nhóm nào?",
    "answer": "Logistic Regression là mô hình phân loại tuyến tính dựa trên sigmoid (cho nhị phân) hoặc softmax (cho đa lớp)."
  },
  {
    "question": "Mô hình Perceptron thuộc nhóm nào?",
    "answer": "Perceptron là mô hình phân loại tuyến tính cơ bản, đưa ra quyết định dựa trên dấu của w^T x + b."
  },
  {
    "question": "Support Vector Machine có phải là mô hình tuyến tính không?",
    "answer": "Đúng, SVM là mô hình phân loại tuyến tính, tìm siêu phẳng phân tách có margin lớn nhất giữa các lớp."
  }
 ]
